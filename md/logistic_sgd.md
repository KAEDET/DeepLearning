# Theanoでロジスティック回帰

- Deep Learning Tutorial 3/4章
- PRMLの第3章線形回帰モデル

- もっとも基本的な分類器で多値分類も可能
- 線形モデルだが入力変数に対して非線形な基底関数との線形結合を考えれば曲線での分類も可能（記事）
- MNISTの数字分類をロジスティック回帰で解くプログラムをTheanoで組むのが目的
- Theanoの基本的な概念が一通り学べる


## MNISTデータのロード

- Deep Learning Tutorial 3章
- 28x28のピクセルデータ、0-255
- トレーニング:50000画像、バリデーション:10000画像、テスト:10000画像に分割
- データは共有変数にロードしておく（GPUが使われる）
- データはfloatにしておく必要がある
- ラベルのようなintデータは取り出す時にintにキャストする

- stg_optimization_mnist()
- load_data()
- 共有変数からのデータの取り出し方
- 可視化の仕方

## ロジスティック回帰モデル

- 2つのパラメータからなる
- 重み行列 W
- バイアスベクトル b

P(Y = i|x, W, b) = softmax_i(W x + b) = \frac{e^{W_i} x + b)}{\sum_j e^{W_j x + b_j}
y_{pred} = argmax_i P(Y = i|x, W, b)

- xはベクトル
- W: (n_in, n_out)    x: (n_in, 1)     b: (n_out, 1)
- softmax関数に通すことでPの合計が1になる
- 確率がもっとも高いクラスに分類する

- LogisticRegression Class
- __init__(): パラメータの初期化（共有変数を使う）
- P(Y = i)の定義、inputはベクトルではなく、行列でまとめてデータを与えてまとめてP(Y)を計算
- y_predの定義
- これらはシンボル（関数の定義のようなもの）
- 変数に格納しているが具体的な値が入るわけではない（printしても意味ない）
- シンボルはtheano.function()で関数化されて初めて呼び出せる


## ロジスティック回帰のパラメータ推定

- 最尤推定法でパラメータを推定する
- 対数尤度関数が最大となるパラメータを推定
- 負の対数尤度関数（コスト関数、誤差関数とみなす）が最小となるパラメータを推定

- negative_log_likelihood(): コスト関数のシンボル
- errors(): テストデータを入れたときのエラー率を返すシンボル

## モデルのトレーニング

- classifierオブジェクトの作成
- トレーニング用の関数をシンボルから構築
- バッチによる勾配降下法
- 訓練データ（バッチ単位）を与えてパラメータを更新、更新後のコストを返す
- パラメータ更新はupdatesでできる
- 数値微分は自分で計算しなくても数値微分してくれる

- バリデーション用の関数をシンボルから構築
- バリデーションデータを入力として与えてエラー率を返す

- テスト用の関数をシンボルから構築
- テストデータを入力として与えてエラー率を返す

## early-stoppingによる収束判定

- 収束するまで同じデータを繰り返し与える
- パラメータ更新をいつ終わりにするかを判定する方法

